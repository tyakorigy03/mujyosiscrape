name: Run Puppeteer Scraper and Commit Output

on:
  workflow_dispatch: # âœ… Manual trigger
  schedule:          # âœ… Automatic every 30 minutes
    - cron: "*/60 * * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¦ Checkout repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: âš™ï¸ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: ğŸ’¾ Cache node_modules
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: ğŸ“¥ Install dependencies
        run: npm install

      - name: ğŸ•¸ï¸ Run scraper
        run: npm run scrape

      - name: ğŸ“ Commit all changed files
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "ğŸ¤– Update scraped data [skip ci]" || echo "No changes to commit"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
